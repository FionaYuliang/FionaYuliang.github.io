<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>python爬虫之：某用户所有微博的简单备份</title>
    <link href="/2021/03/16/python%E7%88%AC%E8%99%AB%E4%B9%8B%EF%BC%9A%E6%9F%90%E7%94%A8%E6%88%B7%E6%89%80%E6%9C%89%E5%BE%AE%E5%8D%9A%E7%9A%84%E7%AE%80%E5%8D%95%E5%A4%87%E4%BB%BD/"/>
    <url>/2021/03/16/python%E7%88%AC%E8%99%AB%E4%B9%8B%EF%BC%9A%E6%9F%90%E7%94%A8%E6%88%B7%E6%89%80%E6%9C%89%E5%BE%AE%E5%8D%9A%E7%9A%84%E7%AE%80%E5%8D%95%E5%A4%87%E4%BB%BD/</url>
    
    <content type="html"><![CDATA[<h3 id="python-爬虫代码"><a href="#python-爬虫代码" class="headerlink" title="python 爬虫代码"></a>python 爬虫代码</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br></pre></td><td class="code"><pre><code class="hljs plain"><br># 目的：编写简易微博备份工具, 将指定微博备份为txt文本<br># 1.  学习python使用<br># 2.  学习使用python获取web页面(学习http调用&#x2F;了解简单网络请求方式&#x2F;使用外部库)<br># 3.  使用python抓取微博接口(了解浏览器抓包方法, http基础规范)<br># 4.  将抓取接口存入数据库中(掌握本地数据库构建存取&#x2F;sql的增删改查写法)<br># 5.  从数据库中读取接口, 输出txt文本<br>import requests<br>import json<br>import time<br>import sqlite3<br>from bs4 import BeautifulSoup<br>def get_page(url):<br>    headers &#x3D; &#123;<br>        &#39;User-Agent&#39;: &#39;Mozilla&#x2F;5.0 (Macintosh Intel Mac OS X 10_14_6) AppleWebKit&#x2F;537.36 (KHTML, like Gecko) Chrome&#x2F;83.0.4103.61 Safari&#x2F;537.36&#39;,<br>        &#39;referer&#39;: &#39;https:&#x2F;&#x2F;m.weibo.cn&#x2F;u&#x2F;6587600437&#39;<br>    &#125;<br>    # target_url &#x3D; &#39;https:&#x2F;&#x2F;m.weibo.cn&#x2F;u&#x2F;1768825052?uid&#x3D;1768825052&amp;luicode&#x3D;10000011&amp;lfid&#x3D;1076031768825052&#39;<br>    res &#x3D; requests.get(url, headers&#x3D;headers)<br>    return res<br>def get_since_id(res):<br>    weibo_json &#x3D; json.loads(res.text)<br>    since_id &#x3D; int(weibo_json[&#39;data&#39;][&#39;cardlistInfo&#39;][&#39;since_id&#39;])<br>    return since_id<br>def get_weibo(res):<br>    weibo_json &#x3D; json.loads(res.text)<br>    weibo_cards &#x3D; weibo_json[&quot;data&quot;][&quot;cards&quot;]<br>    weibo_id &#x3D; []<br>    weibo_time &#x3D; []<br>    weibo_text &#x3D; []<br>    reposts_count &#x3D; []<br>    comments_count &#x3D; []<br>    attitudes_count &#x3D; []<br>    for each in weibo_cards:<br>        weibo_id.append(each[&quot;mblog&quot;][&quot;id&quot;])<br>        weibo_text.append(each[&quot;mblog&quot;][&quot;text&quot;])<br>        weibo_time.append(each[&#39;mblog&#39;][&#39;created_at&#39;])<br>        reposts_count.append(each[&#39;mblog&#39;][&#39;reposts_count&#39;])<br>        comments_count.append(each[&#39;mblog&#39;][&#39;comments_count&#39;])<br>        attitudes_count.append(each[&#39;mblog&#39;][&#39;attitudes_count&#39;])<br>    weibo_matrix &#x3D; [weibo_id, weibo_time, weibo_text,<br>                    reposts_count, comments_count, attitudes_count]<br>    result &#x3D; list(zip(*weibo_matrix))<br>    return result<br>conn &#x3D; sqlite3.connect(&#39;weibo.db&#39;)<br>c &#x3D; conn.cursor()<br>def create_table():<br>    c.execute(&quot;&quot;&quot;CREATE TABLE IF NOT EXISTS weibo_person(<br>        weibo_id int,<br>        created_at text,<br>        weibo_text text,<br>        reposts_count int,<br>        comments_count int,<br>        attitudes_count int<br>        )&quot;&quot;&quot;)<br>def query_and_output():<br>    c.execute(&#39;SELECT * FROM weibo_person&#39;)<br>    data &#x3D; c.fetchall()<br>    c.close()<br>    conn.close()<br>    with open(&#39;&#x2F;Users&#x2F;yao&#x2F;www&#x2F;python&#x2F;微博&#x2F;leftchenn.txt&#39;, &#39;w&#39;, encoding&#x3D;&#39;utf-8&#39;) as file:<br>        for item in data:<br>            string &#x3D; f&#39;发布时间：&#123;item[1]&#125; \n 微博内容：&#123;item[2]&#125; \n 转发数：&#123;item[3]&#125; 评论数：&#123;item[4]&#125; 转发数：&#123;item[5]&#125; \n\n\n &#39;<br>            file.write(string)<br>def main():<br>    host &#x3D; &quot;https:&#x2F;&#x2F;m.weibo.cn&#x2F;u&#x2F;1768825052&quot;<br>    target_url &#x3D; &#39;https:&#x2F;&#x2F;m.weibo.cn&#x2F;api&#x2F;container&#x2F;getIndex?uid&#x3D;1768825052&amp;luicode&#x3D;10000011&amp;lfid&#x3D;1076031768825052&amp;type&#x3D;uid&amp;value&#x3D;1768825052&amp;containerid&#x3D;1076031768825052&#39;<br>    res &#x3D; get_page(target_url)<br>    result &#x3D; get_weibo(res)<br>    since_id &#x3D; get_since_id(res)<br>    for i in range(10):<br>        print(&#39;page &#123;&#125; scraping...&#39;.format(i))<br>        new_url &#x3D; f&#39;https:&#x2F;&#x2F;m.weibo.cn&#x2F;api&#x2F;container&#x2F;getIndex?uid&#x3D;1768825052&amp;luicode&#x3D;10000011&amp;lfid&#x3D;1076031768825052&amp;type&#x3D;uid&amp;value&#x3D;1768825052&amp;containerid&#x3D;1076031768825052&amp;since_id&#x3D;&#123;since_id&#125;&#39;<br>        time.sleep(1)<br>        res &#x3D; get_page(new_url)<br>        result.extend(get_weibo(res))<br>        since_id &#x3D; get_since_id(res)<br>        print(&#39;page &#123;&#125; scrap done...&#39;.format(i))<br>    create_table()<br>    c.executemany(&#39;INSERT INTO weibo_person VALUES(?,?,?,?,?,?)&#39;, result)<br>    conn.commit()<br>    print(&#39;insert successfully...&#39;)<br>    query_and_output()<br>    print(&#39;output successfully...&#39;)<br>if __name__ &#x3D;&#x3D; &quot;__main__&quot;:<br>    main()<br></code></pre></td></tr></table></figure><h3 id="数据库内容"><a href="#数据库内容" class="headerlink" title="数据库内容"></a>数据库内容</h3><p><img src="https://uploader.shimo.im/f/C4lQEFWbuu75xLc6.png!thumbnail?fileGuid=xHYJXDKdjxTKJJHR" alt="weibo.db/weibo_person"></p><h3 id="得到的文本"><a href="#得到的文本" class="headerlink" title="得到的文本"></a>得到的文本</h3><p><img src="https://uploader.shimo.im/f/1gkiCal2TQ1uG2ue.png!thumbnail?fileGuid=xHYJXDKdjxTKJJHR" alt="微博文本"></p>]]></content>
    
    
    
    <tags>
      
      <tag>python</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>python爬虫之：抓取豆瓣电影TOP250</title>
    <link href="/2021/03/16/python%E7%88%AC%E8%99%AB%E4%B9%8B%EF%BC%9A%E6%8A%93%E5%8F%96%E8%B1%86%E7%93%A3%E7%94%B5%E5%BD%B1TOP250/"/>
    <url>/2021/03/16/python%E7%88%AC%E8%99%AB%E4%B9%8B%EF%BC%9A%E6%8A%93%E5%8F%96%E8%B1%86%E7%93%A3%E7%94%B5%E5%BD%B1TOP250/</url>
    
    <content type="html"><![CDATA[<p>豆瓣用户每天都在对“看过”的电影进行“很差”到“力荐”的评价，豆瓣根据每部影片看过的人数以及该影片所得的评价等综合数据，通过算法分析产生豆瓣电影 Top 250。</p><h3 id="原始网页："><a href="#原始网页：" class="headerlink" title="原始网页："></a>原始网页：</h3><p><a href="https://movie.douban.com/top250">https://movie.douban.com/top250</a></p><p><img src="https://uploader.shimo.im/f/YwpUFMDrQ59YL1UA.png!thumbnail?fileGuid=xHYJXDKdjxTKJJHR" alt="图片"></p><h3 id="python-爬虫代码"><a href="#python-爬虫代码" class="headerlink" title="python 爬虫代码"></a>python 爬虫代码</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br></pre></td><td class="code"><pre><code class="hljs plain">import requests<br>from bs4 import BeautifulSoup<br>import sqlite3<br>import time<br>def open_url(url):<br>    headers &#x3D; &#123;<br>        &#39;User-Agent&#39;: &#39;Mozilla&#x2F;5.0 (Macintosh; Intel Mac OS X 10_14_6) AppleWebKit&#x2F;537.36 (KHTML, like Gecko) Chrome&#x2F;83.0.4103.61 Safari&#x2F;537.36&#39;,<br>        &quot;Cookie&quot;: &#39;bid&#x3D;U5nCZ8p0dQU; gr_user_id&#x3D;cb5f0143-dc7b-4558-8ca8-645601af3a4c; _vwo_uuid_v2&#x3D;D8FFB9019ECC277DA812225E3B2109D06|9ff6373ff5de826c9b373e0499c2fd95; __gads&#x3D;ID&#x3D;fca53c413c37e6b3:T&#x3D;1583725810:S&#x3D;ALNI_Ma0O2oj2sLthssNt4FqeaZYp7EL_Q; ll&#x3D;&quot;108288&quot;; douban-fav-remind&#x3D;1; __yadk_uid&#x3D;UtObTTkrwA7qukDAgdd2INMv9LH52PEA; viewed&#x3D;&quot;26829016_26264642_26277694_4315606_1955110_1400498_4065258_1094802_26939853_12411215&quot;; __utmc&#x3D;30149280; __utmc&#x3D;223695111; dbcl2&#x3D;&quot;33304907:UiHXJr1eiGI&quot;; ck&#x3D;PYWO; _pk_ref.100001.4cf6&#x3D;%5B%22%22%2C%22%22%2C1591627160%2C%22https%3A%2F%2Faccounts.douban.com%2Fpassport%2Flogin%3Fredir%3Dhttps%253A%252F%252Fmovie.douban.com%252Ftop250%22%5D; _pk_ses.100001.4cf6&#x3D;*; __utma&#x3D;30149280.542734861.1583725808.1591614666.1591627161.51; __utmb&#x3D;30149280.0.10.1591627161; __utmz&#x3D;30149280.1591627161.51.46.utmcsr&#x3D;accounts.douban.com|utmccn&#x3D;(referral)|utmcmd&#x3D;referral|utmcct&#x3D;&#x2F;passport&#x2F;login; __utma&#x3D;223695111.1397865339.1583730183.1591614666.1591627161.10; __utmb&#x3D;223695111.0.10.1591627161; __utmz&#x3D;223695111.1591627161.10.8.utmcsr&#x3D;accounts.douban.com|utmccn&#x3D;(referral)|utmcmd&#x3D;referral|utmcct&#x3D;&#x2F;passport&#x2F;login; push_noty_num&#x3D;0; push_doumail_num&#x3D;0; _pk_id.100001.4cf6&#x3D;6441328ab4c5f495.1583730182.10.1591627294.1591614962.&#39;,<br>        &#39;Accept&#39;: &#39;text&#x2F;html,application&#x2F;xhtml+xml,application&#x2F;xml;q&#x3D;0.9,image&#x2F;webp,image&#x2F;apng,*&#x2F;*;q&#x3D;0.8,application&#x2F;signed-exchange;v&#x3D;b3;q&#x3D;0.9&#39;<br>    &#125;<br>    res &#x3D; requests.get(url, headers&#x3D;headers)<br>    return res<br>def find_moives(res):<br>    soup &#x3D; BeautifulSoup(res.text, &#39;html.parser&#39;)<br>    # 电影名<br>    movies &#x3D; []<br>    targets &#x3D; soup.find_all(&#39;div&#39;, class_&#x3D;&#39;hd&#39;)<br>    for each in targets:<br>        movies.append(each.a.span.text)<br>    # 评分<br>    ranks &#x3D; []<br>    targets &#x3D; soup.find_all(&#39;em&#39;)<br>    for each in targets:<br>        index &#x3D; int(each.text)<br>        ranks.append(index)<br>    # 资料<br>    profiles &#x3D; []<br>    targets &#x3D; soup.find_all(&#39;div&#39;, class_&#x3D;&#39;bd&#39;)<br>    for each in targets:<br>        try:<br>            profiles.append(each.p.text.split(&#39;\n&#39;)[<br>                1].strip() + each.p.text.split(&#39;\n&#39;)[2].strip())<br>        except:<br>            continue<br>    data_matrix &#x3D; [ranks, movies, profiles]<br>    result &#x3D; list(zip(*data_matrix))<br>    return result<br>def find_depth(res):<br>    soup &#x3D; BeautifulSoup(res.text, &#39;html.parser&#39;)<br>    depth &#x3D; soup.find(<br>        &#39;span&#39;, class_&#x3D;&#39;next&#39;).previous_sibling.previous_sibling.text<br>    return int(depth)<br>conn &#x3D; sqlite3.connect(&quot;douban_movies.db&quot;)<br>c &#x3D; conn.cursor()<br>def create_table():<br>    c.execute(<br>        &quot;CREATE TABLE IF NOT EXISTS douban_movies250(item_id INT,rank INT, movie TEXT, profile TEXT)&quot;)<br>def query_and_output():<br>    c.execute(&#39;SELECT * FROM douban_movies250&#39;)<br>    data &#x3D; c.fetchall()<br>    c.close()<br>    conn.close()<br>    with open(&#39;&#x2F;Users&#x2F;yao&#x2F;www&#x2F;python&#x2F;douban_movies250.txt&#39;, &#39;w&#39;, encoding&#x3D;&#39;utf-8&#39;) as file:<br>        for row in data:<br>            string &#x3D; f&#39;Top &#123;row[1]&#125; : 《&#123;row[2]&#125;》，\n 简介： &#123;row[3]&#125;\n&#39;<br>            file.write(string)<br>def main():<br>    host &#x3D; &#39;https:&#x2F;&#x2F;movie.douban.com&#x2F;top250&#39;<br>    res &#x3D; open_url(host)<br>    depth &#x3D; find_depth(res)<br>    result &#x3D; []<br>    for i in range(depth):<br>        url &#x3D; host + &#39;&#x2F;?start&#x3D;&#39; + str(25 * i)<br>        time.sleep(1)<br>        res &#x3D; open_url(url)<br>        result.extend(find_moives(res))<br>    # item_id &#x3D; [i for i in range(250)]<br>    # result_matrix &#x3D; [item_id, result]<br>    # result &#x3D; list(zip(*result_matrix))<br>    create_table()<br>    c.executemany(&#39;INSERT INTO douban_movies250 VALUES(?,?,?,?)&#39;, result)<br>    conn.commit()<br>    print(&#39;insert database successfully&#39;)<br>    query_and_output()<br>    print(&#39;output successfully &#39;)<br>if __name__ &#x3D;&#x3D; &quot;__main__&quot;:<br>    main()<br></code></pre></td></tr></table></figure><h3 id="得到的文本"><a href="#得到的文本" class="headerlink" title="得到的文本"></a>得到的文本</h3><p><img src="https://uploader.shimo.im/f/ffvcAZnM2U1p7Y5e.png!thumbnail?fileGuid=xHYJXDKdjxTKJJHR" alt="图片"></p>]]></content>
    
    
    
    <tags>
      
      <tag>python</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>python爬虫之：抓取网易云音乐某首歌曲的热门评论</title>
    <link href="/2021/03/16/python%E7%88%AC%E8%99%AB%E4%B9%8B%EF%BC%9A%E6%8A%93%E5%8F%96%E7%BD%91%E6%98%93%E4%BA%91%E9%9F%B3%E4%B9%90%E6%9F%90%E9%A6%96%E6%AD%8C%E6%9B%B2%E7%9A%84%E7%83%AD%E9%97%A8%E8%AF%84%E8%AE%BA/"/>
    <url>/2021/03/16/python%E7%88%AC%E8%99%AB%E4%B9%8B%EF%BC%9A%E6%8A%93%E5%8F%96%E7%BD%91%E6%98%93%E4%BA%91%E9%9F%B3%E4%B9%90%E6%9F%90%E9%A6%96%E6%AD%8C%E6%9B%B2%E7%9A%84%E7%83%AD%E9%97%A8%E8%AF%84%E8%AE%BA/</url>
    
    <content type="html"><![CDATA[<h3 id="首先，以这首歌为例："><a href="#首先，以这首歌为例：" class="headerlink" title="首先，以这首歌为例："></a>首先，以这首歌为例：</h3><p><img src="https://uploader.shimo.im/f/uRWUHpnCGtVrJUzX.png!thumbnail?fileGuid=xHYJXDKdjxTKJJHR" alt="图片"></p><h3 id="python-代码如下："><a href="#python-代码如下：" class="headerlink" title="python 代码如下："></a>python 代码如下：</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><code class="hljs plain">import requests<br>import json<br># import BeautifulSoup from bs4<br>def get_hotComments(res):<br>    comments_json &#x3D; json.loads(res.text)<br>    hot_comments &#x3D; comments_json[&#39;hotComments&#39;]<br>    with open(&#39;&#x2F;Users&#x2F;yao&#x2F;www&#x2F;python&#x2F;evol-love.txt&#39;, &#39;w&#39;, encoding&#x3D;&#39;utf-8&#39;) as file:<br>        for each in hot_comments:<br>            file.write(each[&#39;user&#39;][&#39;nickname&#39;] + &#39;: \n\n&#39;)<br>            file.write(each[&#39;content&#39;] + &#39;\n&#39;)<br>            # file.write(each[&#39;likedCount&#39;] + &#39;\n&#39;)<br>            # file.write(each[&#39;time&#39;] + &#39;\n&#39;)<br>            file.write(&#39;--❤-----------❤--\n&#39;)<br>def get_comments(url):<br>    song_id &#x3D; url.split(&#39;&#x3D;&#39;)[1]<br>    headers &#x3D; &#123;<br>        &#39;user-agent&#39;: &#39;curl https:&#x2F;&#x2F;bootstrap.pypa.io&#x2F;get-pip.py | python3&#39;,<br>        &#39;referer&#39;: &#39;https:&#x2F;&#x2F;music.163.com&#x2F;song?id&#x3D;1381290746&#39;&#125;<br>    params &#x3D; &#39;15S1vG2hDWPcsAeXpjYIcwuRpK7nwElk3Cdy6c&#x2F;3aJdbH5aBub7nWrYPxZQaMzKrhFSUo1n4nGHkCbaZAl77WSFPMYjjv6sU5Qipnqnn4QjXRH6eN1w&#x2F;PcauCCUo4NDgaw&#x2F;Uudad5J&#x2F;zpgDY2005gC3UF+s2s&#x2F;ND5tjXTU0SeDkiBg47A6b6VqhK&#x2F;7E&#x2F;hS9++nlvAC7QkkzCbsXZMp&#x2F;jyBl5+KroeMcGAfFumxZ5pME&#x3D;&#39;<br>    encSecKey &#x3D; &#39;3f5dbdd0ec1f0a1501b88f6e04ce30ecf88192b4e3a92bd2dc1216f2ccc90898211e6347a2ab36d07f93793352ff6559fb927b7cbd337f5887d2af7b442e2dfb0b4abd83e85c6c3bb20fe2beef050db4c169531411f4e23caaa201f62609fcda4de694c8e9e759443fea2f7febf044bd9c4bcb2697519ca96dca676730059156&#39;<br>    data &#x3D; &#123;<br>        &#39;params&#39;: params,<br>        &#39;encSecKey&#39;: encSecKey<br>    &#125;<br>    target_url &#x3D; &#39;https:&#x2F;&#x2F;music.163.com&#x2F;weapi&#x2F;v1&#x2F;resource&#x2F;comments&#x2F;R_SO_4_&#123;&#125;?csrf_token&#x3D;55a6b8514346a9f676c8485978093b9f&#39;.format(song_id)<br>    res &#x3D; requests.post(target_url, headers&#x3D;headers, data&#x3D;data)<br>    # rawHTML &#x3D;  &#39;&#39;<br>    # soup &#x3D; BeautifulSoup(rawHTML)<br>    # file_name_obj &#x3D; soup.select_one(&#39;.f-ff2&#39;)<br>    # file_name &#x3D; file_name_obj.text<br>    return res<br>def main():<br>    url &#x3D; input(&#39;please input song url:&#39;)<br>    res &#x3D; get_comments(url)<br>    # title &#x3D; get_title(url)<br>    get_hotComments(res)<br>if __name__ &#x3D;&#x3D; &quot;__main__&quot;:<br>    main()<br></code></pre></td></tr></table></figure><p>得到的txt文件如下（如有需要可进一步分析）：</p><p><img src="https://uploader.shimo.im/f/1DwdMQXCPNfJwB4s.png!thumbnail?fileGuid=xHYJXDKdjxTKJJHR" alt="图片"></p>]]></content>
    
    
    
    <tags>
      
      <tag>python</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>数组内置排序函数对比</title>
    <link href="/2021/03/16/%E6%95%B0%E7%BB%84%E5%86%85%E7%BD%AE%E6%8E%92%E5%BA%8F%E5%87%BD%E6%95%B0%E5%AF%B9%E6%AF%94/"/>
    <url>/2021/03/16/%E6%95%B0%E7%BB%84%E5%86%85%E7%BD%AE%E6%8E%92%E5%BA%8F%E5%87%BD%E6%95%B0%E5%AF%B9%E6%AF%94/</url>
    
    <content type="html"><![CDATA[<p>PHP 手册专门列出了数组内置排序函数的属性一览表, 不过仔细看就会发现, 这个表格比较乱, 缺乏条理性</p><p><img src="https://uploader.shimo.im/f/n7nDEwPB0t3qbVCA.png!thumbnail?fileGuid=xHYJXDKdjxTKJJHR" alt="图片"></p><p>因此我对这些排序函数做了简单的归类和对比, 这样看起来一目了然, 也仍容易记忆使用了.</p><p><img src="https://uploader.shimo.im/f/8vzoLOQmKVQY6nd0.png!thumbnail?fileGuid=xHYJXDKdjxTKJJHR" alt="图片"></p><p>首先带有 sort 的分为 3 组 6 对, 每对之间是正序/倒序的相反关系,其他属性相同.</p><p>sort 和 asort 的区别是:是否在排序时保持键值关联</p><p>只有 sort/rsort/shuffle 排序不需要考虑键的问题,可随意使用</p><p>用户可自定义排序函数 :usort/uasort/uksort</p><p>natsort/natcasesort 后者的 case 指的是忽略大小写</p><p>array_multisort 的基本排序方式是: arrayA 按照键值大小排序,然后其他 array 都按照 arrayA 的调整策略跟着调整</p><p>参考:<a href="https://www.php.net/manual/zh/array.sorting.php">https://www.php.net/manual/zh/array.sorting.php</a></p>]]></content>
    
    
    
    <tags>
      
      <tag>PHP</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>github-hexo 两小时快速搭建个人博客网站</title>
    <link href="/2021/03/15/github-hexo%20%E4%B8%A4%E5%B0%8F%E6%97%B6%E5%BF%AB%E9%80%9F%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2%E7%BD%91%E7%AB%99/"/>
    <url>/2021/03/15/github-hexo%20%E4%B8%A4%E5%B0%8F%E6%97%B6%E5%BF%AB%E9%80%9F%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2%E7%BD%91%E7%AB%99/</url>
    
    <content type="html"><![CDATA[<p>今天用 2 个小时的时间完成了 Hexo 个人博客的最基本搭建，因此博客的第一篇文章就是与此有关。</p><p>此博客的搭建使用的是 CSDN 上看到的一篇教程：</p><p><a href="https://blog.csdn.net/sinat_37781304/article/details/82729029">https://blog.csdn.net/sinat_37781304/article/details/82729029</a></p><p>该教程名副其实，或许可以称得上“史上最全”，分为三个部分：</p><p>第一部分：hexo 的初级搭建还有部署到 github page 上，以及个人域名的绑定。</p><p>第二部分：hexo 的基本配置，更换主题，实现多终端工作，以及在 coding page 部署实现国内外分流</p><p>第三部分：hexo 添加各种功能，包括搜索的 SEO，阅读量统计，访问量统计和评论系统等。</p><p>此博客部署完成后，如你所见，使用的 github 给定域名，暂未设置个人域名。然后对网站的语言、标题、风格主题等进行了设置。其他扩展功能暂未上线，可以满足最基本的需要。</p><p>以下是 Hexo 搭建步骤，点击教程做起来吧，你也可以轻松拥有自己的网站。</p><ol><li>安装 Git</li><li>安装 Node.js</li><li>安装 Hexo</li><li>GitHub 创建个人仓库</li><li>生成 SSH 添加到 GitHub</li><li>将 hexo 部署到 GitHub</li><li>设置个人域名</li><li>发布文章</li></ol>]]></content>
    
    
    
    <tags>
      
      <tag>github, Hexo</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>python爬虫之：抓取B站高分番剧、视频弹幕图云</title>
    <link href="/2020/08/02/python%E7%88%AC%E8%99%AB%E4%B9%8B%EF%BC%9A%E6%8A%93%E5%8F%96B%E7%AB%99%E9%AB%98%E5%88%86%E7%95%AA%E5%89%A7%E3%80%81%E8%A7%86%E9%A2%91%E5%BC%B9%E5%B9%95%E5%9B%BE%E4%BA%91/"/>
    <url>/2020/08/02/python%E7%88%AC%E8%99%AB%E4%B9%8B%EF%BC%9A%E6%8A%93%E5%8F%96B%E7%AB%99%E9%AB%98%E5%88%86%E7%95%AA%E5%89%A7%E3%80%81%E8%A7%86%E9%A2%91%E5%BC%B9%E5%B9%95%E5%9B%BE%E4%BA%91/</url>
    
    <content type="html"><![CDATA[<h1 id="1-抓取高分番剧"><a href="#1-抓取高分番剧" class="headerlink" title="1.抓取高分番剧"></a>1.抓取高分番剧</h1><h2 id="原始网页"><a href="#原始网页" class="headerlink" title="原始网页"></a>原始网页</h2><p><img src="https://uploader.shimo.im/f/GbrF2IqozjV1j7v0.png!thumbnail?fileGuid=xHYJXDKdjxTKJJHR" alt="番剧列表页"></p><p><a href="https://www.bilibili.com/anime/index/#season_version=-1&area=-1&is_finish=-1&copyright=-1&season_status=-1&season_month=-1&year=-1&style_id=-1&order=4&st=1&sort=0&page=1">https://www.bilibili.com/anime/index/#season_version=-1&amp;area=-1&amp;is_finish=-1&amp;copyright=-1&amp;season_status=-1&amp;season_month=-1&amp;year=-1&amp;style_id=-1&amp;order=4&amp;st=1&amp;sort=0&amp;page=1</a></p><h2 id="python-爬虫代码（储存到数据库）"><a href="#python-爬虫代码（储存到数据库）" class="headerlink" title="python 爬虫代码（储存到数据库）"></a>python 爬虫代码（储存到数据库）</h2><h3 id="主文件-lt-niche-gems-py-gt"><a href="#主文件-lt-niche-gems-py-gt" class="headerlink" title="主文件 &lt;niche_gems.py&gt;"></a>主文件 &lt;niche_gems.py&gt;</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><code class="hljs plain">import requests<br>from bs4 import BeautifulSoup<br>import json<br>import time<br>def getReviewTimes(media_link):<br>    res &#x3D; requests.get(media_link)<br>    soup &#x3D; BeautifulSoup(res.text, &#39;html.parser&#39;)<br>    review_times &#x3D; soup.find_all(&#39;div&#39;, class_&#x3D;&#39;media-info-review-times&#39;)<br>    for i in review_times:<br>        review_time &#x3D; i.text<br>    return review_time<br>def getAnime(url):<br>    res &#x3D; requests.get(url)<br>    graded_data &#x3D; json.loads(res.text)<br>    animes_list &#x3D; graded_data[&#39;data&#39;][&#39;list&#39;]<br>    media_ids &#x3D; []<br>    media_links &#x3D; []<br>    m_orders &#x3D; []<br>    titles &#x3D; []<br>    review_times &#x3D; []<br>    for each in animes_list:<br>        media_id &#x3D; each[&#39;media_id&#39;]<br>        media_ids.append(media_id)<br>        media_link &#x3D; f&#39;https:&#x2F;&#x2F;www.bilibili.com&#x2F;bangumi&#x2F;media&#x2F;md&#123;media_id&#125;&#39;<br>        review_time &#x3D; getReviewTimes(media_link)<br>        review_times.append(review_time)<br>        media_links.append(media_link)<br>        m_order &#x3D; each[&#39;order&#39;].strip()<br>        m_orders.append(m_order)<br>        titles.append(each[&#39;title&#39;])<br>    animes_matrix &#x3D; [media_ids, m_orders, titles, review_times, media_links]<br>    animes_result &#x3D; list(zip(*animes_matrix))<br>    return animes_result<br></code></pre></td></tr></table></figure><h3 id="按照评分-by-score"><a href="#按照评分-by-score" class="headerlink" title="按照评分 by score"></a>按照评分 by score</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><code class="hljs plain"><br>import niche_gems<br>import sqlite3<br>import csv<br>import time<br>conn &#x3D; sqlite3.connect(&#39;anime.db&#39;)<br>c &#x3D; conn.cursor()<br>def createTable():<br>    c.execute(&quot;&quot;&quot;CREATE TABLE IF NOT EXISTS animeByScore(<br>        media_id INTEGER PRIMARY KEY,<br>        m_order REAL,<br>        title TEXT,<br>        review_time INTEGER,<br>        media_link TEXT)&quot;&quot;&quot;)<br>def main():<br>    createTable()<br>    for i in range(1, 90):<br>        print(f&#39;page &#123;i&#125; scraping...&#39;)<br>        url_score &#x3D; f&#39;https:&#x2F;&#x2F;api.bilibili.com&#x2F;pgc&#x2F;season&#x2F;index&#x2F;result?season_version&#x3D;-1&amp;area&#x3D;-1&amp;is_finish&#x3D;-1&amp;copyright&#x3D;-1&amp;season_status&#x3D;-1&amp;season_month&#x3D;-1&amp;year&#x3D;-1&amp;style_id&#x3D;-1&amp;order&#x3D;4&amp;st&#x3D;1&amp;sort&#x3D;0&amp;page&#x3D;&#123;i&#125;&amp;season_type&#x3D;1&amp;pagesize&#x3D;20&amp;type&#x3D;1&#39;<br>        time.sleep(1)<br>        animes_results_by_score &#x3D; []<br>        animes_result_by_score &#x3D; niche_gems.getAnime(url_score)<br>        animes_results_by_score.extend(animes_result_by_score)<br>        c.executemany(&#39;INSERT OR IGNORE INTO animeByScore VALUES(?,?,?,?,?)&#39;,<br>                      animes_results_by_score)<br>        conn.commit()<br>        print(f&#39;page &#123;i&#125; animeByScore insert successfully...&#39;)<br>        print(f&#39;page &#123;i&#125; done...&#39;)<br>    c.close()<br>    conn.close()<br>    print(&#39;执行完毕，数据库已关闭！&#39;)<br>if __name__ &#x3D;&#x3D; &quot;__main__&quot;:<br>    main()<br></code></pre></td></tr></table></figure><h3 id="按照播放量-by-play-count"><a href="#按照播放量-by-play-count" class="headerlink" title="按照播放量 by play count"></a>按照播放量 by play count</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><code class="hljs plain">import niche_gems<br>import sqlite3<br>conn &#x3D; sqlite3.connect(&#39;anime.db&#39;)<br>c &#x3D; conn.cursor()<br>def createTable():<br>    c.execute(&quot;&quot;&quot;CREATE TABLE IF NOT EXISTS animeByPlaycount(<br>        media_id int primary key，<br>        order int,<br>        title text,<br>        review_time int,<br>        media_link text<br>    )&quot;&quot;&quot;)<br>def query_and_output():<br>    c.execute(&#39;SELECT * from animeByPlaycount SORT BY order&#39;)<br>    data &#x3D; c.fetchall()<br>    c.close()<br>    conn.close()<br>    with open(&#39;&#x2F;Users&#x2F;yao&#x2F;www&#x2F;python&#x2F;&#x2F;bilibili&#x2F;anime&#x2F;animeByPlaycount.txt&#39;, &#39;w&#39;, encoding&#x3D;&#39;utf-8&#39;) as file:<br>        for row in data:<br>            file.write()<br>def main():<br>    url_play_count &#x3D; &#39;https:&#x2F;&#x2F;api.bilibili.com&#x2F;pgc&#x2F;season&#x2F;index&#x2F;result?season_version&#x3D;-1&amp;area&#x3D;-1&amp;is_finish&#x3D;-1&amp;copyright&#x3D;-1&amp;season_status&#x3D;-1&amp;season_month&#x3D;-1&amp;year&#x3D;-1&amp;style_id&#x3D;-1&amp;order&#x3D;2&amp;st&#x3D;1&amp;sort&#x3D;0&amp;page&#x3D;1&amp;season_type&#x3D;1&amp;pagesize&#x3D;20&amp;type&#x3D;1&#39;<br>    animes_result_by_playcount &#x3D; niche_gems.getAnime(url_play_count)<br>    createTable()<br>    c.executemany(&#39;INSERT OR IGNORE INTO animeByPlaycount&#39;)<br>    conn.commit()<br>    print(&#39;animeByPlaycount insert successfully...&#39;)<br>    query_and_output()<br>    print(&#39;animeByPlaycount file saved successfully...&#39;)<br>if __name__ &#x3D;&#x3D; &quot;__main__&quot;:<br>    main()<br></code></pre></td></tr></table></figure><h2 id="数据库内容"><a href="#数据库内容" class="headerlink" title="数据库内容"></a>数据库内容</h2><p><img src="https://uploader.shimo.im/f/W9vxXsoi1Nw4XG2b.png!thumbnail?fileGuid=xHYJXDKdjxTKJJHR" alt="animate.db/animateByScore"></p><h2 id="从数据库中取出并展示在-html-中"><a href="#从数据库中取出并展示在-html-中" class="headerlink" title="从数据库中取出并展示在 html 中"></a>从数据库中取出并展示在 html 中</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br></pre></td><td class="code"><pre><code class="hljs plain">import sqlite3<br>import csv<br>import pandas as pd<br>from prettytable import PrettyTable<br>conn &#x3D; sqlite3.connect(&#39;anime.db&#39;)<br>c &#x3D; conn.cursor()<br>c.execute(&#39;SELECT * from animeByScore WHERE m_order &gt; 9.7&#39;)<br>data &#x3D; c.fetchall()<br>c.close()<br>conn.close()<br># file_path &#x3D; &#39;&#x2F;Users&#x2F;yao&#x2F;www&#x2F;python&#x2F;bilibili&#x2F;anime&#x2F;animeByScore.csv&#39;<br># with open(file_path, &#39;w&#39;, newline&#x3D;&#39;&#39;, encoding&#x3D;&#39;utf-8&#39;) as f:<br>#     fieldnames &#x3D; [&#39;anime_id&#39;, &#39;m_order&#39;, &#39;title&#39;, &#39;review_time&#39;, &#39;anime_link&#39;]<br>#     f_csv &#x3D; csv.DictWriter(f, fieldnames&#x3D;fieldnames)<br>#     f_csv.writeheader()<br>#     for row in data:<br>#         f_csv.writerow(<br>#             &#123;<br>#                 &#39;anime_id&#39;: row[0],<br>#                 &#39;m_order&#39;: row[1],<br>#                 &#39;title&#39;: row[2],<br>#                 &#39;review_time&#39;: row[3],<br>#                 &#39;anime_link&#39;: row[4]<br>#             &#125;<br>#         )<br>html_uri &#x3D; &#39;&#x2F;Users&#x2F;yao&#x2F;www&#x2F;python&#x2F;bilibili&#x2F;anime&#x2F;animeByScore.html&#39;<br>record_list &#x3D; data<br>title &#x3D; &quot;评分列表&quot;<br>tbody_content &#x3D; &quot;&quot;<br>for record in record_list:<br>    tbody_content &#x3D; tbody_content + f&quot;&quot;&quot;<br>     &lt;tr&gt;<br>        &lt;td&gt;&#123;record[0]&#125;&lt;&#x2F;td&gt;<br>        &lt;td&gt;&#123;record[1]&#125;&lt;&#x2F;td&gt;<br>        &lt;td&gt;&#123;record[2]&#125;&lt;&#x2F;td&gt;<br>        &lt;td&gt;&#123;record[3]&#125;&lt;&#x2F;td&gt;<br>        &lt;td&gt;&#123;record[4]&#125;&lt;&#x2F;td&gt;<br>    &lt;&#x2F;tr&gt;<br>    &quot;&quot;&quot;<br>content &#x3D; f&quot;&quot;&quot;<br>&lt;table&gt;<br>&lt;thead&gt;<br>    &lt;th&gt;anime_id&lt;&#x2F;th&gt;<br>    &lt;th&gt;m_order&lt;&#x2F;th&gt;<br>    &lt;th&gt;title&lt;&#x2F;th&gt;<br>    &lt;th&gt;review_time&lt;&#x2F;th&gt;<br>    &lt;th&gt;anime_link&lt;&#x2F;th&gt;<br>&lt;&#x2F;thead&gt;<br>&lt;tbody&gt;<br>    &#123;tbody_content&#125;<br>&lt;&#x2F;tbody&gt;<br>&lt;&#x2F;table&gt;<br>&quot;&quot;&quot;<br>html &#x3D; f&quot;&quot;&quot;<br>&lt;!DOCTYPE html&gt;<br>&lt;html lang&#x3D;&quot;zh-CN&quot;&gt;<br>&lt;head&gt;<br>&lt;meta charset&#x3D;&quot;utf-8&quot;&gt;<br>&lt;title&gt;&#123;title&#125;&lt;&#x2F;title&gt;<br>&lt;&#x2F;head&gt;<br>&lt;body&gt;<br>&#123;content&#125;<br>&lt;&#x2F;body&gt;<br>&lt;&#x2F;html&gt;<br>&quot;&quot;&quot;<br>with open(html_uri, &#39;w&#39;, newline&#x3D;&#39;&#39;, encoding&#x3D;&#39;utf-8&#39;) as f:<br>    f.write(html)<br>print(&#39;csv file saved (＾－＾)V&#39;)<br></code></pre></td></tr></table></figure><h2 id="html-展示效果"><a href="#html-展示效果" class="headerlink" title="html 展示效果"></a>html 展示效果</h2><p><img src="https://uploader.shimo.im/f/7piCCurNzIDREWHa.png!thumbnail?fileGuid=xHYJXDKdjxTKJJHR" alt="生成的html"></p><h2 id=""><a href="#" class="headerlink" title=""></a></h2><h2 id="小技巧：如何把-CSV-转换成-HTML"><a href="#小技巧：如何把-CSV-转换成-HTML" class="headerlink" title="小技巧：如何把 CSV 转换成 HTML"></a>小技巧：如何把 CSV 转换成 HTML</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs plain">from prettytable import PrettyTable<br>file_path &#x3D; &#39;&#x2F;Users&#x2F;yao&#x2F;www&#x2F;python&#x2F;bilibili&#x2F;anime&#x2F;animeByScore.csv&#39;<br>csv_file &#x3D; open(file_path, &#39;r&#39;)<br>csv_file &#x3D; csv_file.readlines()<br>tb &#x3D; PrettyTable(csv_file[0].split(&#39;,&#39;))<br># 这一句也可以这么写<br># table &#x3D; PrettyTable()<br># table.field_names&#x3D;csv_file[0].split(&#39;,&#39;)<br>for row in range(1, 100):<br>    csv_file[row] &#x3D; csv_file[row].split(&#39;,&#39;)<br>    tb.add_row(csv_file[row])<br>html_path &#x3D; &#39;&#x2F;Users&#x2F;yao&#x2F;www&#x2F;python&#x2F;bilibili&#x2F;anime&#x2F;html_file.html&#39;<br>html_file &#x3D; open(html_path, &#39;w&#39;)<br>html_code &#x3D; tb.get_html_string()<br>html_file &#x3D; html_file.write(html_code)<br></code></pre></td></tr></table></figure><h1 id="2-抓取视频弹幕并制作图云"><a href="#2-抓取视频弹幕并制作图云" class="headerlink" title="2.抓取视频弹幕并制作图云"></a>2.抓取视频弹幕并制作图云</h1><h2 id="python-爬虫弹幕"><a href="#python-爬虫弹幕" class="headerlink" title="python 爬虫弹幕"></a>python 爬虫弹幕</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><code class="hljs plain">import requests<br>import json<br>import re<br><br>def get_cid(url):<br>    bvid &#x3D; url.split(&#39;&#x2F;&#39;)[4].split(&#39;?&#39;)[0]<br>    danmu_page_link &#x3D; f&#39;https:&#x2F;&#x2F;api.bilibili.com&#x2F;x&#x2F;player&#x2F;pagelist?bvid&#x3D;&#123;bvid&#125;&amp;jsonp&#x3D;jsonp&#39;<br>    res &#x3D; requests.get(danmu_page_link)<br>    cid_page &#x3D; json.loads(res.text)<br>    cid &#x3D; cid_page[&#39;data&#39;][0][&#39;cid&#39;]<br>    # 获取cid时要注意视频是不是多p,自己做小工具时用其中1p就可以<br>    # cids &#x3D; res_dict[&#39;data&#39;][&#39;cid&#39;]<br>    # part_names &#x3D; res_dict[&#39;data&#39;][&#39;part&#39;]<br>    return cid<br>def get_danmu(cid):<br>    danmu_url &#x3D; f&#39;https:&#x2F;&#x2F;api.bilibili.com&#x2F;x&#x2F;v1&#x2F;dm&#x2F;list.so?oid&#x3D;&#123;cid&#125;&#39;<br>    res &#x3D; requests.get(danmu_url)<br>    res_xml &#x3D; res.content.decode(&#39;utf-8&#39;)<br>    pattern &#x3D; re.compile(&#39;&lt;d.*?&gt;(.*?)&lt;&#x2F;d&gt;&#39;)<br>    danmu_list &#x3D; pattern.findall(res_xml)<br>    return danmu_list<br>def save_file(danmu_list):<br>    file_path &#x3D; &#39;&#x2F;Users&#x2F;yao&#x2F;www&#x2F;python&#x2F;bilibili&#x2F;video&#x2F;danmu_file.txt&#39;<br>    with open(file_path, &#39;w&#39;, encoding&#x3D;&#39;utf-8&#39;) as file:<br>        for item in danmu_list:<br>            file.write(item)<br>            file.write(&#39;\n&#39;)<br>def main():<br>    source &#x3D; &#39;https:&#x2F;&#x2F;www.bilibili.com&#x2F;video&#x2F;BV1xs411Q799?p&#x3D;1&#39;<br>    cid &#x3D; get_cid(source)<br>    danmu_list &#x3D; get_danmu(cid)<br>    save_file(danmu_list)<br>    print(&#39;file saved successfully...&#39;)<br>if __name__ &#x3D;&#x3D; &#39;__main__&#39;:<br>    main()<br></code></pre></td></tr></table></figure><h3 id="-1"><a href="#-1" class="headerlink" title=""></a></h3><h2 id="得到的弹幕文本"><a href="#得到的弹幕文本" class="headerlink" title="得到的弹幕文本"></a>得到的弹幕文本</h2><p><img src="https://uploader.shimo.im/f/bmL7w8bGEIt6pI8V.png!thumbnail?fileGuid=xHYJXDKdjxTKJJHR" alt="弹幕文本"></p><h3 id="弹幕文本图云分析"><a href="#弹幕文本图云分析" class="headerlink" title="弹幕文本图云分析"></a>弹幕文本图云分析</h3><h3 id="分词代码"><a href="#分词代码" class="headerlink" title="分词代码"></a>分词代码</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs plain">import jieba<br>from wordcloud import WordCloud<br>file_path &#x3D; &#39;&#x2F;Users&#x2F;yao&#x2F;www&#x2F;python&#x2F;bilibili&#x2F;video&#x2F;danmu_file.txt&#39;<br>with open(file_path, &#39;r&#39;, encoding&#x3D;&#39;utf-8&#39;) as file:<br>    text_str &#x3D; file.read()<br>seg_list &#x3D; jieba.cut(text_str)<br>word_str &#x3D; &quot; &quot;.join(seg_list)<br>font_path &#x3D; &quot;&#x2F;System&#x2F;Library&#x2F;Fonts&#x2F;PingFang.ttc&quot;<br>wc_settintg &#x3D; &#123;<br>    &#39;font_path&#39;: &#39;&#x2F;System&#x2F;Library&#x2F;Fonts&#x2F;PingFang.ttc&#39;,<br>    &#39;background_color&#39;: &#39;white&#39;,<br>    &#39;width&#39;: 1000,<br>    &#39;height&#39;: 860,<br>    &#39;margin&#39;: 2,<br>&#125;<br>wc &#x3D; WordCloud(**wc_settintg).generate(word_str)<br>wc.to_file(&#39;&#x2F;Users&#x2F;yao&#x2F;www&#x2F;python&#x2F;bilibili&#x2F;video&#x2F;xiaojiayu_python_p1.png&#39;)<br>print(&#39;wordcloud done&#39;)<br></code></pre></td></tr></table></figure><p>参考视频：<a href="https://www.bilibili.com/video/BV1g7411e7m4">https://www.bilibili.com/video/BV1g7411e7m4</a></p><h3 id="得到的图云"><a href="#得到的图云" class="headerlink" title="得到的图云"></a>得到的图云</h3><p>（B 站的好多弹幕真是越来越不能看了……）</p><p><img src="https://uploader.shimo.im/f/DvLCgWmCYqB4RbJl.png!thumbnail?fileGuid=xHYJXDKdjxTKJJHR" alt="图片"></p><h3 id="遇到的问题：生成的图片-中文乱码"><a href="#遇到的问题：生成的图片-中文乱码" class="headerlink" title="遇到的问题：生成的图片 中文乱码"></a>遇到的问题：生成的图片 中文乱码</h3><p>查了一下这是因为中文字体包不适配，然后发现我们用 mac 自带的苹方字体就能非常简单的搞定。做词云的时候用的 Mac，所以 Windows 的解决方法没有尝试。</p><p>本地路径是：</p><p>font_path = “/System/Library/Fonts/PingFang.ttc”</p><p><img src="https://uploader.shimo.im/f/gnsjnKTW75l7CnJb.png!thumbnail?fileGuid=xHYJXDKdjxTKJJHR" alt="本地路径"></p><p>在电脑中查看：</p><ol><li>启动台——其他——打开字体册</li></ol><p><img src="https://uploader.shimo.im/f/IXg7PFlvLltkqEYG.png!thumbnail?fileGuid=xHYJXDKdjxTKJJHR" alt="Mac的字体册"></p><ol start="2"><li>如果你之前没有改过系统字体的话，默认选中苹方简体，右键选择在 Finder 中显示</li></ol><p><img src="https://uploader.shimo.im/f/JNHIQbkInbc4WQWN.png!thumbnail?fileGuid=xHYJXDKdjxTKJJHR" alt="选择字体"></p><p><img src="https://uploader.shimo.im/f/ReT6XWuT8VPw0dTs.png!thumbnail?fileGuid=xHYJXDKdjxTKJJHR" alt="需要的字体包"></p><p>这就是我们需要的字体包。</p><p>如果不需要其他参数的话，字体路径直接传入 WordCloud()参数就可以了。</p><p>wc = WordCloud(font_path).generate(word_str)</p><p>词云官方文档地址：<a href="https://github.com/amueller/word_cloud">https://github.com/amueller/word_cloud</a></p>]]></content>
    
    
    
    <tags>
      
      <tag>python</tag>
      
    </tags>
    
  </entry>
  
  
  
  
</search>
